_target_: model.BigModel
pretrained_backbone_name: "vit_b_16"
frozen: false
head:
  _target_: model.MLP
  initial_out_features: 20
  sizes: [768, 100]
  layers: ["Normal"]
  head_type: Normal
  activation: 
    _target_: torch.nn.ReLU